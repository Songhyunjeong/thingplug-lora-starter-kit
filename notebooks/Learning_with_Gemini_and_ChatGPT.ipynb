{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Songhyunjeong/thingplug-lora-starter-kit/blob/master/notebooks/Learning_with_Gemini_and_ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Use Gemini and ChatGPT to learn from two capable teachers</b>\n",
        "\n",
        "Use Google's latest model release, Gemini, to teach you what you want to know and compare those with ChatGPT's responses.\n",
        "\n",
        "The models are specifically prompted not to generate extra text to make it easier to compare any differences."
      ],
      "metadata": {
        "id": "ZWhWniBGu3_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Gemini API key\n",
        "\n",
        "# access your Gemini API key\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_secret_name = 'G_Secret_key'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY=userdata.get(gemini_api_secret_name)\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'''Secret not found\\n\\nThis expects you to create a secret named {gemini_api_secret_name} in Colab\\n\\nVisit https://makersuite.google.com/app/apikey to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {gemini_api_secret_name}''')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'''You need to grant this notebook access to the {gemini_api_secret_name} secret in order for the notebook to access Gemini on your behalf.''')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {gemini_api_secret_name} stored in Colab and it's a valid key from https://makersuite.google.com/app/apikey\")\n",
        "  raise e\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "HAg5Vlk-TjdX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "JpQ3d-L_luVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "rPP1vRVfia91",
        "outputId": "d30059d4-1c5c-426a-9528-30e41f949ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/328.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "userdata.get('Secret_key')\n",
        "import os # Import the os module to access environment variables\n",
        "openai_api_secret_name = 'Secret_key'\n",
        "OPENAI_API_KEY=userdata.get(openai_api_secret_name)\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "my_assistant = client.beta.assistants.create(\n",
        "    instructions=\"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n",
        "    name=\"Math Tutor\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],\n",
        "    model=\"gpt-4-turbo\",\n",
        ")\n",
        "print(my_assistant)"
      ],
      "metadata": {
        "id": "xfOmWF3xiO79",
        "outputId": "b7501098-e184-4eb9-ab07-fceb944c6432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant(id='asst_2sOVfwfyjqTC4UjzITBIbR3L', created_at=1720429210, description=None, instructions='You are a personal math tutor. When asked a question, write and run Python code to answer the question.', metadata={}, model='gpt-4-turbo', name='Math Tutor', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_assistant_id = \"asst_2sOVfwfyjqTC4UjzITBIbR3L\"  # 실제 어시스턴트 ID로 변경\n",
        "\n",
        "def ask_math_question(question):\n",
        "    thread = client.beta.threads.create()  # 새 스레드 생성\n",
        "\n",
        "    # 질문 메시지 추가\n",
        "    client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=question\n",
        "    )\n",
        "\n",
        "    # 어시스턴트 실행\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=my_assistant_id\n",
        "    )\n",
        "\n",
        "    # 실행 완료될 때까지 대기 (필요한 경우 timeout 설정)\n",
        "    import time\n",
        "    while True:\n",
        "        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "        if run_status.status == \"completed\":\n",
        "            break\n",
        "        time.sleep(1)  # 1초 대기\n",
        "\n",
        "    # 답변 가져오기\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    answer = messages.data[0].content[0].text.value  # 답변 추출\n",
        "\n",
        "    return answer\n",
        "\n",
        "# 질문 예시\n",
        "question = \"2차 방정식 x^2 + 2x - 3 = 0의 해를 구해주고 풀이과정을 작성해줘.\"\n",
        "answer = ask_math_question(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "BttGihYhnjKp",
        "outputId": "e10ad0cf-9d63-4ca4-d3f9-ac29f99aed18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2차 방정식 \\(x^2 + 2x - 3 = 0\\) 의 해는 \\(x = 1\\) 과 \\(x = -3\\) 입니다.\n",
            "\n",
            "### 풀이 과정\n",
            "1. 주어진 2차 방정식은 \\(x^2 + 2x - 3 = 0\\) 입니다.\n",
            "2. 근의 공식에 사용되는 변수 \\(a\\), \\(b\\), \\(c\\) 는 각각 1, 2, -3 입니다.\n",
            "3. 근의 공식은 다음과 같습니다:\n",
            "   \\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]\n",
            "4. 이때 판별식 \\( \\Delta = b^2 - 4ac \\) 을 계산하면,\n",
            "   \\[ \\Delta = 2^2 - 4 \\cdot 1 \\cdot (-3) = 4 + 12 = 16 \\]\n",
            "5. 판별식의 제곱근 \\( \\sqrt{\\Delta} \\) 은 4입니다.\n",
            "6. 그러므로, 두 근은 다음과 같이 계산됩니다:\n",
            "   \\[\n",
            "   x_1 = \\frac{-2 + 4}{2 \\times 1} = 1, \\quad\n",
            "   x_2 = \\frac{-2 - 4}{2 \\times 1} = -3\n",
            "   \\]\n",
            "\n",
            "따라서, 이 방정식의 두 해는 1과 -3입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure OpenAI API key\n",
        "\n",
        "# access your OpenAI API key\n",
        "\n",
        "# installing llmx first isn't necessary but avoids a confusing error when installing openai\n",
        "!pip install -q llmx\n",
        "!pip install -q openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "openai_api_secret_name = 'Secret_key'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  OPENAI_API_KEY=userdata.get(openai_api_secret_name)\n",
        "  client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        "  )\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'''Secret not found\\n\\nThis expects you to create a secret named {openai_api_secret_name} in Colab\\n\\nVisit https://platform.openai.com/api-keys to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {openai_api_secret_name}''')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'''You need to grant this notebook access to the {openai_api_secret_name} secret in order for the notebook to access Gemini on your behalf.''')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {openai_api_secret_name} stored in Colab and it's a valid key from https://platform.openai.com/api-keys\")\n",
        "  raise e\n"
      ],
      "metadata": {
        "id": "yFv1abRcv2P2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ask a question!\n",
        "\n",
        "text = '구구단 계산기 작성 파이썬 코드 작성해줘' # @param {type:\"string\"}\n",
        "\n",
        "# ask Gemini\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "response = chat.send_message('%s -- Please answer as concisely as you can, avoiding any extra conversation or text' % text)\n",
        "gemini_response = response.text\n",
        "\n",
        "# ask ChatGPT\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": '%s -- Please answer as concisely as you can, avoiding any extra conversation or text' % text}\n",
        "  ]\n",
        ")\n",
        "\n",
        "openai_response = completion.choices[0].message.content\n",
        "\n",
        "# render the diff\n",
        "\n",
        "# importing these every execution is unnecessary but avoids another notebook cell\n",
        "from IPython.display import HTML\n",
        "import difflib\n",
        "\n",
        "# omit the legend to slim down the UI\n",
        "difflib.HtmlDiff._legend = ''\n",
        "\n",
        "HTML(difflib.HtmlDiff().make_file(gemini_response.splitlines(), openai_response.splitlines(), 'Gemini', 'ChatGPT'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "timFyiyRYEqz",
        "outputId": "87643605-a3ce-41b1-e9b1-5cbb5d14a360"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
              "          \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
              "\n",
              "<html>\n",
              "\n",
              "<head>\n",
              "    <meta http-equiv=\"Content-Type\"\n",
              "          content=\"text/html; charset=utf-8\" />\n",
              "    <title></title>\n",
              "    <style type=\"text/css\">\n",
              "        table.diff {font-family:Courier; border:medium;}\n",
              "        .diff_header {background-color:#e0e0e0}\n",
              "        td.diff_header {text-align:right}\n",
              "        .diff_next {background-color:#c0c0c0}\n",
              "        .diff_add {background-color:#aaffaa}\n",
              "        .diff_chg {background-color:#ffff77}\n",
              "        .diff_sub {background-color:#ffaaaa}\n",
              "    </style>\n",
              "</head>\n",
              "\n",
              "<body>\n",
              "    \n",
              "    <table class=\"diff\" id=\"difflib_chg_to1__top\"\n",
              "           cellspacing=\"0\" cellpadding=\"0\" rules=\"groups\" >\n",
              "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
              "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
              "        <thead><tr><th class=\"diff_next\"><br /></th><th colspan=\"2\" class=\"diff_header\">Gemini</th><th class=\"diff_next\"><br /></th><th colspan=\"2\" class=\"diff_header\">ChatGPT</th></tr></thead>\n",
              "        <tbody>\n",
              "            <tr><td class=\"diff_next\" id=\"difflib_chg_to1__0\"><a href=\"#difflib_chg_to1__0\">f</a></td><td class=\"diff_header\" id=\"from1_1\">1</td><td nowrap=\"nowrap\">```python</td><td class=\"diff_next\"><a href=\"#difflib_chg_to1__0\">f</a></td><td class=\"diff_header\" id=\"to1_1\">1</td><td nowrap=\"nowrap\">```python</td></tr>\n",
              "            <tr><td class=\"diff_next\"><a href=\"#difflib_chg_to1__top\">t</a></td><td class=\"diff_header\" id=\"from1_2\">2</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">def&nbsp;multiplication_table(n):</span></td><td class=\"diff_next\"><a href=\"#difflib_chg_to1__top\">t</a></td><td class=\"diff_header\" id=\"to1_2\">2</td><td nowrap=\"nowrap\"><span class=\"diff_add\">num&nbsp;=&nbsp;int(input(\"구구단을&nbsp;출력할&nbsp;숫자를&nbsp;입력하세요:&nbsp;\"))</span></td></tr>\n",
              "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_3\">3</td><td nowrap=\"nowrap\"><span class=\"diff_add\">&nbsp;</span></td></tr>\n",
              "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_3\">3</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;</span>for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;<span class=\"diff_sub\">n+</span>1):</td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_4\">4</td><td nowrap=\"nowrap\">for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;1<span class=\"diff_add\">0</span>):</td></tr>\n",
              "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_4\">4</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;j&nbsp;in&nbsp;range(1,&nbsp;n+1):</span></td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_5\">5</td><td nowrap=\"nowrap\"><span class=\"diff_add\">&nbsp;&nbsp;&nbsp;&nbsp;print(f\"{num}&nbsp;x&nbsp;{i}&nbsp;=&nbsp;{num&nbsp;*&nbsp;i}\")</span></td></tr>\n",
              "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_5\">5</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(i&nbsp;*&nbsp;j,&nbsp;end=\"&nbsp;\")</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
              "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_6\">6</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print()</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
              "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_7\">7</td><td nowrap=\"nowrap\">```</td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_6\">6</td><td nowrap=\"nowrap\">```</td></tr>\n",
              "        </tbody>\n",
              "    </table>\n",
              "</body>\n",
              "\n",
              "</html>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so3XNmIP4kVk",
        "outputId": "db63c077-609b-4cde-84da-9ef3241f7458"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}